{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes homework with Yelp review text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read `yelp.csv` into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access yelp.csv in your data directory and load it into a DataFrame\n",
    "import pandas as pd\n",
    "path = '/Users/arthurkolios/documents/data_science/GA-SEA-DAT1/data/'\n",
    "yelp = pd.read_csv(path + 'yelp.csv')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the 5-star and 1-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the DataFrame to only rows that have a 5-star or 1-star rating. Using an OR condition\n",
    "yelp51 = yelp[(yelp.stars==1) | (yelp.stars==5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Split the new DataFrame into training and testing sets, using the review text as the only feature and the star rating as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = yelp51['text']\n",
    "y = yelp51.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create document-term matrices from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t1\n",
      "  (0, 301)\t1\n",
      "  (0, 670)\t1\n",
      "  (0, 723)\t1\n",
      "  (0, 798)\t3\n",
      "  (0, 997)\t2\n",
      "  (0, 1971)\t2\n",
      "  (0, 3625)\t1\n",
      "  (0, 4647)\t5\n",
      "  (0, 4699)\t1\n",
      "  (0, 4791)\t1\n",
      "  (0, 5282)\t2\n",
      "  (0, 5955)\t1\n",
      "  (0, 6081)\t1\n",
      "  (0, 6497)\t1\n",
      "  (0, 6800)\t2\n",
      "  (0, 6957)\t2\n",
      "  (0, 7555)\t2\n",
      "  (0, 7912)\t1\n",
      "  (0, 8317)\t2\n",
      "  (0, 8318)\t2\n",
      "  (0, 8613)\t1\n",
      "  (0, 9428)\t1\n",
      "  (0, 9783)\t1\n",
      "  (0, 10202)\t1\n",
      "  :\t:\n",
      "  (3063, 5017)\t1\n",
      "  (3063, 5577)\t1\n",
      "  (3063, 5757)\t1\n",
      "  (3063, 6403)\t1\n",
      "  (3063, 6504)\t2\n",
      "  (3063, 6623)\t1\n",
      "  (3063, 7895)\t2\n",
      "  (3063, 7912)\t1\n",
      "  (3063, 8717)\t1\n",
      "  (3063, 8925)\t1\n",
      "  (3063, 9783)\t1\n",
      "  (3063, 10128)\t1\n",
      "  (3063, 10202)\t1\n",
      "  (3063, 10274)\t1\n",
      "  (3063, 10389)\t1\n",
      "  (3063, 12509)\t1\n",
      "  (3063, 13412)\t1\n",
      "  (3063, 14021)\t1\n",
      "  (3063, 14450)\t2\n",
      "  (3063, 14858)\t4\n",
      "  (3063, 14865)\t1\n",
      "  (3063, 14913)\t1\n",
      "  (3063, 15716)\t1\n",
      "  (3063, 15843)\t1\n",
      "  (3063, 16063)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 869)\t3\n",
      "  (0, 1262)\t1\n",
      "  (0, 1554)\t1\n",
      "  (0, 3899)\t1\n",
      "  (0, 4763)\t1\n",
      "  (0, 5282)\t2\n",
      "  (0, 5429)\t1\n",
      "  (0, 6464)\t1\n",
      "  (0, 6678)\t2\n",
      "  (0, 7555)\t1\n",
      "  (0, 8129)\t1\n",
      "  (0, 8734)\t1\n",
      "  (0, 9428)\t1\n",
      "  (0, 10202)\t1\n",
      "  (0, 10341)\t1\n",
      "  (0, 10412)\t2\n",
      "  (0, 11112)\t1\n",
      "  (0, 11883)\t1\n",
      "  (0, 12653)\t1\n",
      "  (0, 13072)\t1\n",
      "  (0, 14149)\t2\n",
      "  (0, 14858)\t1\n",
      "  (0, 14913)\t1\n",
      "  (0, 15047)\t2\n",
      "  :\t:\n",
      "  (1021, 13671)\t1\n",
      "  (1021, 13835)\t2\n",
      "  (1021, 14021)\t1\n",
      "  (1021, 14051)\t1\n",
      "  (1021, 14555)\t1\n",
      "  (1021, 14697)\t1\n",
      "  (1021, 14853)\t3\n",
      "  (1021, 14858)\t9\n",
      "  (1021, 14865)\t2\n",
      "  (1021, 14868)\t1\n",
      "  (1021, 14881)\t7\n",
      "  (1021, 14913)\t1\n",
      "  (1021, 15047)\t4\n",
      "  (1021, 15068)\t2\n",
      "  (1021, 15706)\t1\n",
      "  (1021, 16087)\t1\n",
      "  (1021, 16136)\t1\n",
      "  (1021, 16144)\t1\n",
      "  (1021, 16195)\t2\n",
      "  (1021, 16230)\t1\n",
      "  (1021, 16272)\t1\n",
      "  (1021, 16336)\t1\n",
      "  (1021, 16395)\t2\n",
      "  (1021, 16416)\t1\n",
      "  (1021, 16540)\t3\n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train, but only transform X_test\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "print X_train_dtm\n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use Naive Bayes to predict the star rating for reviews in the testing set, and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import/instantiate/fit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931506849315\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Calculate the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 5, 5, 1, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test contains fives and ones, which will confuse the roc_auc_score function\n",
    "y_test[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create y_test_binary, which contains ones and zeros instead\n",
    "y_test_binary = y_test.map({5:1,1:0})\n",
    "y_test_binary[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0398561,  0.9999238,  1.       , ...,  0.9999992,  1.       ,  1.       ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict class probabilities\n",
    "nb.predict_proba(X_test_dtm)\n",
    "\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950356865942\n"
     ]
    }
   ],
   "source": [
    "# calculate the AUC using y_test_binary and y_pred_prob\n",
    "from sklearn import metrics\n",
    "print metrics.roc_auc_score(y_test_binary, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.03351955  0.03351955  0.03351955  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.04469274  0.04469274\n",
      "  0.04469274  0.04469274  0.04469274  0.04469274  0.04469274  0.04469274\n",
      "  0.04469274  0.04469274  0.04469274  0.04469274  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05586592  0.05586592  0.05586592  0.05586592\n",
      "  0.05586592  0.05586592  0.05586592  0.05586592  0.05586592  0.05586592\n",
      "  0.05586592  0.06145251  0.06145251  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.0726257   0.0726257\n",
      "  0.0726257   0.0726257   0.0726257   0.0726257   0.0726257   0.07821229\n",
      "  0.07821229  0.07821229  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08938547  0.08938547  0.08938547\n",
      "  0.08938547  0.08938547  0.08938547  0.08938547  0.08938547  0.08938547\n",
      "  0.08938547  0.09497207  0.09497207  0.09497207  0.09497207  0.09497207\n",
      "  0.09497207  0.09497207  0.09497207  0.09497207  0.10055866  0.10055866\n",
      "  0.10055866  0.10055866  0.10055866  0.10055866  0.10055866  0.10055866\n",
      "  0.10055866  0.10055866  0.10055866  0.10055866  0.10614525  0.10614525\n",
      "  0.10614525  0.10614525  0.10614525  0.11173184  0.11173184  0.11173184\n",
      "  0.11173184  0.11173184  0.11731844  0.11731844  0.11731844  0.11731844\n",
      "  0.11731844  0.11731844  0.11731844  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12849162  0.12849162\n",
      "  0.12849162  0.12849162  0.12849162  0.13407821  0.13407821  0.13407821\n",
      "  0.1396648   0.1396648   0.1396648   0.1396648   0.1452514   0.15083799\n",
      "  0.15083799  0.15642458  0.15642458  0.15642458  0.15642458  0.15642458\n",
      "  0.15642458  0.15642458  0.15642458  0.15642458  0.15642458  0.15642458\n",
      "  0.15642458  0.15642458  0.16201117  0.16759777  0.16759777  0.17318436\n",
      "  0.17318436  0.17877095  0.17877095  0.18435754  0.18994413  0.18994413\n",
      "  0.18994413  0.19553073  0.19553073  0.19553073  0.20111732  0.20111732\n",
      "  0.20111732  0.20111732  0.20670391  0.2122905   0.21787709  0.21787709\n",
      "  0.21787709  0.21787709  0.22346369  0.22905028  0.23463687  0.23463687\n",
      "  0.23463687  0.24022346  0.24022346  0.24022346  0.24022346  0.24581006\n",
      "  0.25139665  0.25698324  0.26256983  0.26256983  0.26256983  0.26256983\n",
      "  0.26815642  0.27374302  0.27374302  0.27932961  0.2849162   0.29050279\n",
      "  0.29050279  0.29608939  0.30167598  0.30167598  0.30726257  0.31284916\n",
      "  0.31284916  0.31284916  0.31843575  0.32402235  0.32960894  0.32960894\n",
      "  0.32960894  0.33519553  0.34078212  0.34636872  0.35195531  0.35195531\n",
      "  0.3575419   0.36312849  0.36871508  0.36871508  0.36871508  0.37430168\n",
      "  0.37430168  0.37988827  0.38547486  0.39106145  0.39664804  0.40223464\n",
      "  0.40223464  0.40782123  0.41340782  0.41899441  0.42458101  0.4301676\n",
      "  0.4301676   0.43575419  0.44134078  0.44692737  0.45251397  0.45810056\n",
      "  0.46368715  0.46927374  0.46927374  0.47486034  0.48044693  0.48603352\n",
      "  0.49162011  0.4972067   0.4972067   0.5027933   0.50837989  0.51396648\n",
      "  0.51955307  0.52513966  0.53072626  0.53631285  0.54189944  0.54748603\n",
      "  0.55307263  0.55865922  0.55865922  0.56424581  0.5698324   0.57541899\n",
      "  0.58100559  0.58659218  0.59217877  0.59776536  0.60335196  0.60893855\n",
      "  0.61452514  0.62011173  0.62011173  0.62011173  0.62569832  0.63128492\n",
      "  0.63687151  0.6424581   0.64804469  0.65363128  0.65921788  0.66480447\n",
      "  0.67039106  0.67597765  0.68156425  0.68715084  0.69273743  0.69832402\n",
      "  0.70391061  0.70949721  0.7150838   0.72067039  0.72625698  0.73184358\n",
      "  0.73743017  0.74301676  0.74860335  0.75418994  0.75977654  0.76536313\n",
      "  0.77094972  0.77653631  0.78212291  0.7877095   0.80446927  1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAGJCAYAAAAaBkAzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzAAnBWZmZpZxUmBmZmYA/H8/+SI5YpTl1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109c35a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve using y_test_binary and y_pred_prob\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_binary, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "print fpr\n",
    "#print(metrics.roc_curve(y_test_binary, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Print the confusion matrix, and calculate the sensitivity and specificity. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 125  54]\n",
      " [  0  16 827]\n",
      " [  0   0   0]]\n",
      "[ 0.          0.03351955  0.03351955  0.03351955  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615  0.03910615\n",
      "  0.03910615  0.03910615  0.03910615  0.03910615  0.04469274  0.04469274\n",
      "  0.04469274  0.04469274  0.04469274  0.04469274  0.04469274  0.04469274\n",
      "  0.04469274  0.04469274  0.04469274  0.04469274  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933  0.05027933\n",
      "  0.05027933  0.05027933  0.05586592  0.05586592  0.05586592  0.05586592\n",
      "  0.05586592  0.05586592  0.05586592  0.05586592  0.05586592  0.05586592\n",
      "  0.05586592  0.06145251  0.06145251  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911  0.06703911\n",
      "  0.06703911  0.06703911  0.06703911  0.06703911  0.0726257   0.0726257\n",
      "  0.0726257   0.0726257   0.0726257   0.0726257   0.0726257   0.07821229\n",
      "  0.07821229  0.07821229  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888  0.08379888\n",
      "  0.08379888  0.08379888  0.08379888  0.08938547  0.08938547  0.08938547\n",
      "  0.08938547  0.08938547  0.08938547  0.08938547  0.08938547  0.08938547\n",
      "  0.08938547  0.09497207  0.09497207  0.09497207  0.09497207  0.09497207\n",
      "  0.09497207  0.09497207  0.09497207  0.09497207  0.10055866  0.10055866\n",
      "  0.10055866  0.10055866  0.10055866  0.10055866  0.10055866  0.10055866\n",
      "  0.10055866  0.10055866  0.10055866  0.10055866  0.10614525  0.10614525\n",
      "  0.10614525  0.10614525  0.10614525  0.11173184  0.11173184  0.11173184\n",
      "  0.11173184  0.11173184  0.11731844  0.11731844  0.11731844  0.11731844\n",
      "  0.11731844  0.11731844  0.11731844  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503  0.12290503\n",
      "  0.12290503  0.12290503  0.12290503  0.12290503  0.12849162  0.12849162\n",
      "  0.12849162  0.12849162  0.12849162  0.13407821  0.13407821  0.13407821\n",
      "  0.1396648   0.1396648   0.1396648   0.1396648   0.1452514   0.15083799\n",
      "  0.15083799  0.15642458  0.15642458  0.15642458  0.15642458  0.15642458\n",
      "  0.15642458  0.15642458  0.15642458  0.15642458  0.15642458  0.15642458\n",
      "  0.15642458  0.15642458  0.16201117  0.16759777  0.16759777  0.17318436\n",
      "  0.17318436  0.17877095  0.17877095  0.18435754  0.18994413  0.18994413\n",
      "  0.18994413  0.19553073  0.19553073  0.19553073  0.20111732  0.20111732\n",
      "  0.20111732  0.20111732  0.20670391  0.2122905   0.21787709  0.21787709\n",
      "  0.21787709  0.21787709  0.22346369  0.22905028  0.23463687  0.23463687\n",
      "  0.23463687  0.24022346  0.24022346  0.24022346  0.24022346  0.24581006\n",
      "  0.25139665  0.25698324  0.26256983  0.26256983  0.26256983  0.26256983\n",
      "  0.26815642  0.27374302  0.27374302  0.27932961  0.2849162   0.29050279\n",
      "  0.29050279  0.29608939  0.30167598  0.30167598  0.30726257  0.31284916\n",
      "  0.31284916  0.31284916  0.31843575  0.32402235  0.32960894  0.32960894\n",
      "  0.32960894  0.33519553  0.34078212  0.34636872  0.35195531  0.35195531\n",
      "  0.3575419   0.36312849  0.36871508  0.36871508  0.36871508  0.37430168\n",
      "  0.37430168  0.37988827  0.38547486  0.39106145  0.39664804  0.40223464\n",
      "  0.40223464  0.40782123  0.41340782  0.41899441  0.42458101  0.4301676\n",
      "  0.4301676   0.43575419  0.44134078  0.44692737  0.45251397  0.45810056\n",
      "  0.46368715  0.46927374  0.46927374  0.47486034  0.48044693  0.48603352\n",
      "  0.49162011  0.4972067   0.4972067   0.5027933   0.50837989  0.51396648\n",
      "  0.51955307  0.52513966  0.53072626  0.53631285  0.54189944  0.54748603\n",
      "  0.55307263  0.55865922  0.55865922  0.56424581  0.5698324   0.57541899\n",
      "  0.58100559  0.58659218  0.59217877  0.59776536  0.60335196  0.60893855\n",
      "  0.61452514  0.62011173  0.62011173  0.62011173  0.62569832  0.63128492\n",
      "  0.63687151  0.6424581   0.64804469  0.65363128  0.65921788  0.66480447\n",
      "  0.67039106  0.67597765  0.68156425  0.68715084  0.69273743  0.69832402\n",
      "  0.70391061  0.70949721  0.7150838   0.72067039  0.72625698  0.73184358\n",
      "  0.73743017  0.74301676  0.74860335  0.75418994  0.75977654  0.76536313\n",
      "  0.77094972  0.77653631  0.78212291  0.7877095   0.80446927  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "y_test_binary\n",
    "conf_mat =  metrics.confusion_matrix(y_test_binary, y_pred_class)\n",
    "print conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843\n",
      "827\n",
      "0.981020166074\n"
     ]
    }
   ],
   "source": [
    "# calculate sensitivity - True positive rate\n",
    "sum1 = conf_mat[1].sum()\n",
    "print sum1\n",
    "tp = conf_mat[1][2]\n",
    "print tp\n",
    "sensitivity = tp/(sum1*1.0)\n",
    "print sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698324022346\n"
     ]
    }
   ],
   "source": [
    "# calculate specificity (1 - False Positive Rate)\n",
    "sum2 = conf_mat[0].sum()\n",
    "fp = conf_mat[0][2]\n",
    "fpr2 = fp/(sum2*1.0)\n",
    "specificity = 1-fpr2\n",
    "print specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is having a much easier time detecting five-star reviews than one-star reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "\n",
    "Browse through the review text for some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any theories about why the model is incorrectly classifying these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6820    There are few resources in Arizona for dancers...\n",
      "9846    NO.  Don't go. Don't do it.  This was my first...\n",
      "3647    I went in once looking for Canidae.  Which acc...\n",
      "5121    Just isn't very good.\\n\\nI don't understand wh...\n",
      "765     I am not a fan of this place. I like to try to...\n",
      "7130    I was not impressed. The food was bad & expens...\n",
      "3654    pretentious and bad service - attendants are t...\n",
      "4227    I have literally never seen this place open an...\n",
      "5882    Tried Shorty's today, sadly it will be my one ...\n",
      "7188    Simply stated..............a GREASY burger fro...\n",
      "7141    Let me first say that we are fans of the W Hot...\n",
      "753     I went today to meet my daughter for lunch.  W...\n",
      "289     I'd say I've been to the Clubhouse a few times...\n",
      "4686                UPDATE: This location is closed. Boo!\n",
      "7803    I'm sad to report that we dined here for lunch...\n",
      "4249    AMC Theaters has the distinct disadvantage in ...\n",
      "1608    The reviews were so good that my friend and I ...\n",
      "8955    I would not recommend this place to anyone.  I...\n",
      "190     What a load of absolutely hideous, uninteresti...\n",
      "8910    Im going to have to agree Whole heartedly. And...\n",
      "6229    Forget the yogurt and the berry berry bad serv...\n",
      "4031    One star would be giving it a holiday gift!\\n\\...\n",
      "9296    My boyfriend and I tried this place last year ...\n",
      "8291    Hot Breakfast..........NOT, Again cold food wh...\n",
      "5079    Banfield is okay for routine check ups for mai...\n",
      "7827    As you walk in you are greeted by a sign that ...\n",
      "3357    I wrote a less than stellar review about this ...\n",
      "1963                       Prices are often way too high!\n",
      "3634    Seriously?! With grocery stores like Fresh & E...\n",
      "7035    Totally excited to try this place out, my gran...\n",
      "5955    I've now tried Thai Elephant three times.  My ...\n",
      "1270    Maybe I should have had a hot dog but I crave ...\n",
      "1747    This dog park gets one star.Why?Because the la...\n",
      "5257    Remember how I said that the Trivia was the be...\n",
      "2725    I have heard so many good reviews for this pla...\n",
      "3938    We were so disappointed!  We were on vacation ...\n",
      "4374    Cadillac Ranch looked really awesome from the ...\n",
      "4842    My fiance and I tried the place because of a G...\n",
      "2999    I can't even believe I actually went to this r...\n",
      "4562    despite it's billing as the 'largest thrift st...\n",
      "5185    We were driving around Chandler area to find a...\n",
      "943     Don't waste your time...Arrowhead mall on the ...\n",
      "7631    this is a business located in the fry's grocer...\n",
      "4766                                       Very bad food!\n",
      "8741    They served us stale rice.  Average main dishe...\n",
      "6076    Lots of \"gay on gay\" homophobia here.  Hick ba...\n",
      "1527    The portions are too small, the plasticware ju...\n",
      "8441    NOTE: This review concerns the Roberto's on Un...\n",
      "7579    Ok, im not getting the great reviews on this p...\n",
      "8507                         This location is now closed.\n",
      "5011                   Poor service-small portions-pricey\n",
      "1159    I don't like the pizza hear and if you go for ...\n",
      "528                 food is ok, but service is very slow!\n",
      "948     Hey Thai Elephant! Stop sucking! You used to b...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print message text for the false positives\n",
    "pd.set_option('display.max_seq_items', 100)\n",
    "print X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that words like \"crave\", \"cool\", \"good\", \"enjoy\", \"rave\" and \"OMG\" were associated in the training model with good reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2902    Southwest blows its competitors so far out of ...\n",
       "6355                   Yeah, its BBB....what else to say?\n",
       "9765    You can't give anything less than 5 stars to a...\n",
       "3052    When I met some friends for dinner at this res...\n",
       "696     This is the only auto repair place I've ever s...\n",
       "8404    Bruce saved my day, my computer crashed this m...\n",
       "9937    I know Kerrie through my networking and we ben...\n",
       "7300    Decided to call CityWide based on positive onl...\n",
       "357     Called these guys when an evap cooler water pr...\n",
       "1404    Excellent customer service, super clean, and t...\n",
       "9622    I always buy my tires at Walmart, but they did...\n",
       "921     Just because i feel like doing something diffe...\n",
       "2790    John did a fantastic job on figuring out my ov...\n",
       "4938    DUDE..where is the manga....where are the card...\n",
       "2504    I've passed by prestige nails in walmart 100s ...\n",
       "402     Once again Wildflower proves why it's my favor...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the false negatives, it looks like, in some cases, words like \"horribly\", \"terrible\" and \"hate\" were associated with negative reviews in the training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "\n",
    "Let's pretend that you want to balance sensitivity and specificity. You can achieve this by changing the threshold for predicting a 5-star review. What threshold approximately balances sensitivity and specificity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         thresholds        diff\n",
      "count  4.260000e+02  426.000000\n",
      "mean   7.517791e-01    0.079560\n",
      "std    3.982111e-01    0.305886\n",
      "min    1.942358e-34   -1.000000\n",
      "25%    5.337807e-01   -0.155677\n",
      "50%    9.983440e-01    0.012164\n",
      "75%    9.999780e-01    0.275713\n",
      "max    2.000000e+00    1.000000\n"
     ]
    }
   ],
   "source": [
    "# create a list that will store the results of the process below\n",
    "# loop through the thresholds returned by the metrics.roc_curve function\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "#y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "tup = []\n",
    "for index, values in enumerate(thresholds):\n",
    "    sens = tpr[index]\n",
    "    spec = (1-fpr[index])\n",
    "    diff = sens - spec\n",
    "    X = [values,(sens-spec)]\n",
    "    tup.append(X)\n",
    "\n",
    "tup2 = pd.DataFrame(tup, columns = (['thresholds','diff']))\n",
    "print tup2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       thresholds      diff\n",
      "206  9.985983e-01  0.002253\n",
      "207  9.985761e-01  0.003439\n",
      "208  9.985456e-01  0.004626\n",
      "209  9.984385e-01  0.005812\n",
      "210  9.984059e-01  0.006998\n",
      "211  9.984008e-01  0.008184\n",
      "212  9.983633e-01  0.009371\n",
      "213  9.983247e-01  0.014957\n",
      "214  9.982801e-01  0.016143\n",
      "215  9.981286e-01  0.017330\n",
      "216  9.980586e-01  0.018516\n",
      "217  9.980081e-01  0.019702\n",
      "218  9.979851e-01  0.020888\n",
      "219  9.977156e-01  0.022075\n",
      "220  9.975290e-01  0.023261\n",
      "221  9.975280e-01  0.024447\n",
      "222  9.972252e-01  0.025633\n",
      "223  9.968247e-01  0.026820\n",
      "224  9.966896e-01  0.028006\n",
      "225  9.966687e-01  0.029192\n",
      "226  9.960426e-01  0.030378\n",
      "227  9.958523e-01  0.031565\n",
      "228  9.957291e-01  0.032751\n",
      "229  9.954480e-01  0.033937\n",
      "230  9.953947e-01  0.035123\n",
      "231  9.952793e-01  0.036310\n",
      "232  9.948605e-01  0.037496\n",
      "233  9.948268e-01  0.038682\n",
      "234  9.945539e-01  0.039868\n",
      "235  9.933298e-01  0.041054\n",
      "..            ...       ...\n",
      "396  7.740658e-05  0.636872\n",
      "397  6.287978e-05  0.642458\n",
      "398  5.336824e-05  0.648045\n",
      "399  4.258053e-05  0.653631\n",
      "400  3.863692e-05  0.659218\n",
      "401  2.742199e-05  0.664804\n",
      "402  1.524873e-05  0.670391\n",
      "403  6.924004e-06  0.675978\n",
      "404  5.800302e-06  0.681564\n",
      "405  5.635360e-06  0.687151\n",
      "406  4.433656e-06  0.692737\n",
      "407  3.097017e-06  0.698324\n",
      "408  2.473627e-06  0.703911\n",
      "409  2.255361e-06  0.709497\n",
      "410  2.118619e-06  0.715084\n",
      "411  1.901249e-06  0.720670\n",
      "412  1.873873e-06  0.726257\n",
      "413  1.307399e-06  0.731844\n",
      "414  1.234746e-06  0.737430\n",
      "415  9.558343e-07  0.743017\n",
      "416  9.170203e-07  0.748603\n",
      "417  7.907947e-07  0.754190\n",
      "418  5.441042e-07  0.759777\n",
      "419  4.572900e-07  0.765363\n",
      "420  1.413880e-07  0.770950\n",
      "421  9.479122e-08  0.776536\n",
      "422  8.007044e-08  0.782123\n",
      "423  6.288441e-08  0.787709\n",
      "424  2.602244e-08  0.804469\n",
      "425  1.942358e-34  1.000000\n",
      "\n",
      "[220 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# locate the minimum difference (at which sensitivity and specificity are balanced)\n",
    "# pick rows>0\n",
    "print tup2[tup2['diff']>0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity and specificity are balanced with threshold = 9.985983e-01 , with a sensitivity-specificity difference of 0.002253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "\n",
    "Let's see how well Naive Bayes performs when all reviews are included, rather than just 1-star and 5-star reviews:\n",
    "\n",
    "- Define X and y using the original DataFrame from step 1. (y should contain 5 different classes.)\n",
    "- Split the data into training and testing sets.\n",
    "- Calculate the testing accuracy of a Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy.\n",
    "- Print the confusion matrix.\n",
    "- Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y using the original DataFrame\n",
    "# define X and y\n",
    "X = yelp['text']\n",
    "y = yelp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 898)\t1\n",
      "  (0, 1101)\t1\n",
      "  (0, 1120)\t2\n",
      "  (0, 1122)\t2\n",
      "  (0, 1262)\t5\n",
      "  (0, 1371)\t1\n",
      "  (0, 1392)\t1\n",
      "  (0, 2328)\t2\n",
      "  (0, 2341)\t1\n",
      "  (0, 2398)\t1\n",
      "  (0, 2642)\t1\n",
      "  (0, 2711)\t1\n",
      "  (0, 3105)\t2\n",
      "  (0, 3779)\t1\n",
      "  (0, 3785)\t1\n",
      "  (0, 3916)\t1\n",
      "  (0, 4307)\t1\n",
      "  (0, 4352)\t2\n",
      "  (0, 4454)\t3\n",
      "  (0, 4475)\t1\n",
      "  (0, 4995)\t1\n",
      "  (0, 5642)\t1\n",
      "  (0, 6218)\t1\n",
      "  (0, 7130)\t1\n",
      "  (0, 7607)\t2\n",
      "  :\t:\n",
      "  (7499, 21340)\t1\n",
      "  (7499, 21698)\t1\n",
      "  (7499, 21816)\t1\n",
      "  (7499, 22010)\t1\n",
      "  (7499, 22115)\t2\n",
      "  (7499, 22426)\t1\n",
      "  (7499, 22709)\t1\n",
      "  (7499, 22834)\t11\n",
      "  (7499, 22879)\t1\n",
      "  (7499, 22920)\t2\n",
      "  (7499, 22935)\t1\n",
      "  (7499, 23064)\t1\n",
      "  (7499, 23125)\t2\n",
      "  (7499, 23509)\t1\n",
      "  (7499, 24078)\t1\n",
      "  (7499, 24143)\t1\n",
      "  (7499, 24272)\t1\n",
      "  (7499, 24632)\t1\n",
      "  (7499, 24701)\t3\n",
      "  (7499, 24762)\t2\n",
      "  (7499, 24843)\t2\n",
      "  (7499, 24904)\t1\n",
      "  (7499, 24967)\t1\n",
      "  (7499, 25156)\t1\n",
      "  (7499, 25362)\t1\n",
      "  (0, 1064)\t1\n",
      "  (0, 1262)\t5\n",
      "  (0, 1951)\t1\n",
      "  (0, 2016)\t1\n",
      "  (0, 2373)\t1\n",
      "  (0, 2563)\t1\n",
      "  (0, 2702)\t1\n",
      "  (0, 3294)\t1\n",
      "  (0, 3779)\t1\n",
      "  (0, 4335)\t1\n",
      "  (0, 4425)\t1\n",
      "  (0, 4559)\t1\n",
      "  (0, 4680)\t1\n",
      "  (0, 5032)\t1\n",
      "  (0, 6234)\t1\n",
      "  (0, 6491)\t1\n",
      "  (0, 8178)\t1\n",
      "  (0, 8201)\t1\n",
      "  (0, 8690)\t1\n",
      "  (0, 9167)\t1\n",
      "  (0, 9415)\t1\n",
      "  (0, 10008)\t1\n",
      "  (0, 10238)\t1\n",
      "  (0, 10521)\t1\n",
      "  (0, 10927)\t2\n",
      "  :\t:\n",
      "  (2499, 13385)\t3\n",
      "  (2499, 13441)\t1\n",
      "  (2499, 13509)\t1\n",
      "  (2499, 15035)\t1\n",
      "  (2499, 15375)\t1\n",
      "  (2499, 15688)\t1\n",
      "  (2499, 15689)\t1\n",
      "  (2499, 15989)\t1\n",
      "  (2499, 17050)\t1\n",
      "  (2499, 17111)\t1\n",
      "  (2499, 17113)\t1\n",
      "  (2499, 17516)\t1\n",
      "  (2499, 18958)\t1\n",
      "  (2499, 19086)\t1\n",
      "  (2499, 19184)\t1\n",
      "  (2499, 19456)\t1\n",
      "  (2499, 19579)\t1\n",
      "  (2499, 19863)\t1\n",
      "  (2499, 19957)\t1\n",
      "  (2499, 22834)\t6\n",
      "  (2499, 22920)\t2\n",
      "  (2499, 23068)\t1\n",
      "  (2499, 23651)\t1\n",
      "  (2499, 25432)\t2\n",
      "  (2499, 25446)\t1\n"
     ]
    }
   ],
   "source": [
    "# create document-term matrices\n",
    "# import and instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "# fit and transform X_train, but only transform X_test\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "print X_train_dtm\n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4692\n"
     ]
    }
   ],
   "source": [
    "# calculate the testing accuary\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    832\n",
      "5    819\n",
      "3    396\n",
      "2    248\n",
      "1    205\n",
      "Name: stars, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    0.3328\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the null accuracy\n",
    "print y_test.value_counts()\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix\n",
    "conf_mat=metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity =0.273170731707\n"
     ]
    }
   ],
   "source": [
    " #calculate sensitivity - True positive rate (for 1 star reviews)\n",
    "sum1 = conf_mat[0].sum()\n",
    "tp = conf_mat[0][0]\n",
    "sensitivity = tp/(sum1*1.0)\n",
    "print 'sensitivity =' + str(sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity = 0.90243902439\n"
     ]
    }
   ],
   "source": [
    "# calculate specificity (1 - False Positive Rate)\n",
    "sum2 = conf_mat[0].sum()\n",
    "fp = conf_mat[0][2]\n",
    "fpr2 = fp/(sum2*1.0)\n",
    "specificity = 1-fpr2\n",
    "print 'specificity = ' + str(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: This model has a far lower accuracy rate (0.47) than the previous model (0.93). The problems seem to lie on the sensitivity side, with a very low true positive rate of 0.27. It does much better on the specificity side, with a specificity level of 0.902.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
