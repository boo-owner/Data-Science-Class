{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes homework with Yelp review text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read `yelp.csv` into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access yelp.csv in your data directory and load it into a DataFrame\n",
    "import pandas as pd\n",
    "path = '/Users/arthurkolios/documents/data_science/GA-SEA-DAT1/data/'\n",
    "yelp = pd.read_csv(path + 'yelp.csv')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the 5-star and 1-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the DataFrame to only rows that have a 5-star or 1-star rating. Using an OR condition\n",
    "yelp51 = yelp[(yelp.stars==1) | (yelp.stars==5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Split the new DataFrame into training and testing sets, using the review text as the only feature and the star rating as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = yelp51['text']\n",
    "y = yelp51.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create document-term matrices from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 802)\t1\n",
      "  (0, 1410)\t1\n",
      "  (0, 1514)\t1\n",
      "  (0, 1561)\t1\n",
      "  (0, 1654)\t1\n",
      "  (0, 2002)\t1\n",
      "  (0, 2300)\t1\n",
      "  (0, 3651)\t1\n",
      "  (0, 4746)\t1\n",
      "  (0, 5620)\t1\n",
      "  (0, 5976)\t1\n",
      "  (0, 6158)\t1\n",
      "  (0, 6556)\t1\n",
      "  (0, 6675)\t1\n",
      "  (0, 8782)\t1\n",
      "  (0, 8816)\t1\n",
      "  (0, 9740)\t1\n",
      "  (0, 9849)\t1\n",
      "  (0, 10268)\t1\n",
      "  (0, 10339)\t1\n",
      "  (0, 10472)\t1\n",
      "  (0, 10835)\t1\n",
      "  (0, 10939)\t1\n",
      "  (0, 11747)\t1\n",
      "  (0, 13117)\t1\n",
      "  :\t:\n",
      "  (3063, 15220)\t3\n",
      "  (3063, 15225)\t1\n",
      "  (3063, 15449)\t1\n",
      "  (3063, 15518)\t1\n",
      "  (3063, 15696)\t1\n",
      "  (3063, 15822)\t1\n",
      "  (3063, 15823)\t1\n",
      "  (3063, 15881)\t1\n",
      "  (3063, 15894)\t1\n",
      "  (3063, 16107)\t2\n",
      "  (3063, 16146)\t2\n",
      "  (3063, 16152)\t1\n",
      "  (3063, 16260)\t1\n",
      "  (3063, 16264)\t1\n",
      "  (3063, 16308)\t1\n",
      "  (3063, 16327)\t1\n",
      "  (3063, 16401)\t1\n",
      "  (3063, 16440)\t1\n",
      "  (3063, 16460)\t1\n",
      "  (3063, 16489)\t1\n",
      "  (3063, 16547)\t1\n",
      "  (3063, 16578)\t1\n",
      "  (3063, 16648)\t1\n",
      "  (3063, 16672)\t7\n",
      "  (3063, 16680)\t4\n",
      "  (0, 72)\t1\n",
      "  (0, 221)\t2\n",
      "  (0, 789)\t1\n",
      "  (0, 802)\t9\n",
      "  (0, 984)\t1\n",
      "  (0, 985)\t1\n",
      "  (0, 1048)\t1\n",
      "  (0, 1064)\t1\n",
      "  (0, 1155)\t1\n",
      "  (0, 1313)\t1\n",
      "  (0, 1410)\t1\n",
      "  (0, 1519)\t1\n",
      "  (0, 1521)\t2\n",
      "  (0, 1556)\t1\n",
      "  (0, 1588)\t1\n",
      "  (0, 1593)\t1\n",
      "  (0, 2226)\t1\n",
      "  (0, 2258)\t2\n",
      "  (0, 2300)\t1\n",
      "  (0, 2408)\t1\n",
      "  (0, 3543)\t1\n",
      "  (0, 3550)\t2\n",
      "  (0, 3651)\t2\n",
      "  (0, 3964)\t1\n",
      "  (0, 4426)\t1\n",
      "  :\t:\n",
      "  (1020, 16672)\t3\n",
      "  (1020, 16680)\t4\n",
      "  (1021, 802)\t2\n",
      "  (1021, 1271)\t1\n",
      "  (1021, 1558)\t2\n",
      "  (1021, 1702)\t1\n",
      "  (1021, 1951)\t1\n",
      "  (1021, 2489)\t1\n",
      "  (1021, 3493)\t1\n",
      "  (1021, 4219)\t1\n",
      "  (1021, 4456)\t1\n",
      "  (1021, 5327)\t1\n",
      "  (1021, 5359)\t1\n",
      "  (1021, 5976)\t1\n",
      "  (1021, 6853)\t1\n",
      "  (1021, 6982)\t1\n",
      "  (1021, 7008)\t2\n",
      "  (1021, 7552)\t1\n",
      "  (1021, 7956)\t2\n",
      "  (1021, 10164)\t1\n",
      "  (1021, 14979)\t2\n",
      "  (1021, 15132)\t1\n",
      "  (1021, 15169)\t1\n",
      "  (1021, 16235)\t3\n",
      "  (1021, 16401)\t1\n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train, but only transform X_test\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "print X_train_dtm\n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use Naive Bayes to predict the star rating for reviews in the testing set, and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import/instantiate/fit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930528375734\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Calculate the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 1, 5, 5, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test contains fives and ones, which will confuse the roc_auc_score function\n",
    "y_test[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create y_test_binary, which contains ones and zeros instead\n",
    "y_test_binary = y_test.map({5:1,1:0})\n",
    "y_test_binary[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.99970444,  1.        , ...,  1.        ,\n",
       "        0.00812685,  0.99999896])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict class probabilities\n",
    "nb.predict_proba(X_test_dtm)\n",
    "\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936582864821\n"
     ]
    }
   ],
   "source": [
    "# calculate the AUC using y_test_binary and y_pred_prob\n",
    "from sklearn import metrics\n",
    "print metrics.roc_auc_score(y_test_binary, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.03636364  0.03636364  0.03636364  0.03636364  0.03636364\n",
      "  0.04242424  0.04242424  0.04242424  0.04242424  0.04848485  0.04848485\n",
      "  0.05454545  0.06060606  0.06060606  0.06060606  0.06060606  0.06666667\n",
      "  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667\n",
      "  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667\n",
      "  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667\n",
      "  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667\n",
      "  0.06666667  0.06666667  0.06666667  0.07272727  0.07272727  0.07272727\n",
      "  0.07272727  0.07272727  0.07272727  0.07272727  0.07272727  0.07272727\n",
      "  0.07272727  0.07272727  0.07272727  0.07272727  0.07272727  0.07272727\n",
      "  0.07272727  0.07272727  0.07272727  0.07272727  0.07272727  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788  0.07878788\n",
      "  0.08484848  0.08484848  0.08484848  0.08484848  0.08484848  0.08484848\n",
      "  0.08484848  0.08484848  0.08484848  0.08484848  0.09090909  0.09090909\n",
      "  0.09090909  0.0969697   0.0969697   0.0969697   0.0969697   0.0969697\n",
      "  0.0969697   0.0969697   0.0969697   0.0969697   0.0969697   0.0969697\n",
      "  0.0969697   0.0969697   0.0969697   0.0969697   0.0969697   0.0969697\n",
      "  0.0969697   0.0969697   0.0969697   0.0969697   0.0969697   0.0969697\n",
      "  0.0969697   0.0969697   0.0969697   0.0969697   0.0969697   0.0969697\n",
      "  0.0969697   0.1030303   0.1030303   0.1030303   0.1030303   0.10909091\n",
      "  0.10909091  0.11515152  0.11515152  0.11515152  0.11515152  0.11515152\n",
      "  0.11515152  0.11515152  0.11515152  0.12121212  0.12121212  0.12121212\n",
      "  0.12121212  0.12121212  0.12121212  0.12121212  0.12121212  0.12121212\n",
      "  0.12121212  0.12121212  0.12121212  0.12121212  0.12121212  0.12121212\n",
      "  0.12121212  0.12121212  0.12121212  0.12121212  0.12727273  0.12727273\n",
      "  0.13333333  0.13333333  0.13333333  0.13333333  0.13939394  0.13939394\n",
      "  0.13939394  0.14545455  0.14545455  0.14545455  0.14545455  0.14545455\n",
      "  0.14545455  0.14545455  0.14545455  0.15151515  0.15151515  0.15151515\n",
      "  0.15151515  0.15757576  0.15757576  0.15757576  0.15757576  0.15757576\n",
      "  0.15757576  0.15757576  0.16363636  0.16363636  0.16969697  0.16969697\n",
      "  0.16969697  0.16969697  0.16969697  0.16969697  0.16969697  0.16969697\n",
      "  0.16969697  0.16969697  0.16969697  0.16969697  0.16969697  0.16969697\n",
      "  0.17575758  0.17575758  0.17575758  0.17575758  0.17575758  0.17575758\n",
      "  0.17575758  0.17575758  0.17575758  0.17575758  0.17575758  0.17575758\n",
      "  0.17575758  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818\n",
      "  0.18787879  0.18787879  0.18787879  0.19393939  0.2         0.2\n",
      "  0.20606061  0.20606061  0.20606061  0.20606061  0.20606061  0.20606061\n",
      "  0.21212121  0.21818182  0.21818182  0.21818182  0.22424242  0.22424242\n",
      "  0.22424242  0.22424242  0.22424242  0.22424242  0.22424242  0.22424242\n",
      "  0.23030303  0.23030303  0.23030303  0.23030303  0.23636364  0.23636364\n",
      "  0.24242424  0.24848485  0.24848485  0.24848485  0.25454545  0.25454545\n",
      "  0.26060606  0.26060606  0.26060606  0.26666667  0.27272727  0.27878788\n",
      "  0.27878788  0.28484848  0.28484848  0.28484848  0.28484848  0.28484848\n",
      "  0.28484848  0.29090909  0.2969697   0.3030303   0.30909091  0.30909091\n",
      "  0.30909091  0.30909091  0.31515152  0.31515152  0.31515152  0.32121212\n",
      "  0.32121212  0.32121212  0.32727273  0.32727273  0.32727273  0.32727273\n",
      "  0.33333333  0.33939394  0.33939394  0.34545455  0.35151515  0.35151515\n",
      "  0.35757576  0.36363636  0.36363636  0.36969697  0.36969697  0.37575758\n",
      "  0.38181818  0.38181818  0.38787879  0.38787879  0.39393939  0.39393939\n",
      "  0.4         0.40606061  0.41212121  0.41818182  0.41818182  0.42424242\n",
      "  0.43030303  0.43636364  0.44242424  0.44848485  0.45454545  0.45454545\n",
      "  0.46060606  0.46666667  0.47272727  0.47878788  0.48484848  0.49090909\n",
      "  0.4969697   0.5030303   0.50909091  0.51515152  0.52121212  0.52121212\n",
      "  0.52727273  0.53333333  0.53333333  0.53939394  0.54545455  0.55151515\n",
      "  0.55757576  0.56363636  0.56969697  0.57575758  0.58181818  0.58787879\n",
      "  0.59393939  0.59393939  0.59393939  0.6         0.60606061  0.61212121\n",
      "  0.61818182  0.62424242  0.63030303  0.63636364  0.64242424  0.64848485\n",
      "  0.65454545  0.66060606  0.66666667  0.67272727  0.67878788  0.68484848\n",
      "  0.69090909  0.6969697   0.7030303   0.70909091  0.71515152  0.72121212\n",
      "  0.72727273  0.73333333  0.73939394  0.74545455  0.75151515  0.75757576\n",
      "  0.76363636  0.76969697  0.77575758  0.78181818  0.78787879  0.79393939\n",
      "  0.79393939  0.8         0.8         0.80606061  0.81212121  0.81818182\n",
      "  0.82424242  0.83030303  0.83636364  0.84242424  0.84848485  0.85454545\n",
      "  0.85454545  0.86060606  1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAGJCAYAAAAaBkAzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108ef74d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve using y_test_binary and y_pred_prob\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_binary, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "print fpr\n",
    "#print(metrics.roc_curve(y_test_binary, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Print the confusion matrix, and calculate the sensitivity and specificity. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 109  56]\n",
      " [  0  15 842]\n",
      " [  0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "y_test_binary\n",
    "conf_mat =  metrics.confusion_matrix(y_test_binary, y_pred_class)\n",
    "print conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857\n",
      "842\n",
      "0.982497082847\n"
     ]
    }
   ],
   "source": [
    "# calculate sensitivity - True positive rate\n",
    "sum1 = conf_mat[1].sum()\n",
    "print sum1\n",
    "tp = conf_mat[1][2]\n",
    "print tp\n",
    "sensitivity = tp/(sum1*1.0)\n",
    "print sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660606060606\n"
     ]
    }
   ],
   "source": [
    "# calculate specificity (1 - False Positive Rate)\n",
    "sum2 = conf_mat[0].sum()\n",
    "fp = conf_mat[0][2]\n",
    "fpr2 = fp/(sum2*1.0)\n",
    "specificity = 1-fpr2\n",
    "print specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is having a much easier time detecting five-star reviews than one-star reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "\n",
    "Browse through the review text for some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any theories about why the model is incorrectly classifying these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5977    You want good food? You'd be better off smuggl...\n",
      "140     Other than the really great happy hour prices,...\n",
      "1372    No offense to everyone who gave this place 5 s...\n",
      "4630    I used to always go here for tires until my me...\n",
      "7513    Closed on Sunday?  Looks like you've not only ...\n",
      "8626                       sslowest drive through ever!!!\n",
      "8943    Went to Sol for restaurant week.  Was less tha...\n",
      "507     HELLISH HELLISH SUMMER WEATHER (March thru Oct...\n",
      "8514                                      Out of business\n",
      "2297    This is a sad excuse for a gay resort.  Sort o...\n",
      "1187    Needs a new name - now.  \\n\\nThe Pischke's of ...\n",
      "3238    Soggy flavorless pizza served on unwarmed cera...\n",
      "7739    So, there's no negative stars, too bad. Tried ...\n",
      "4686                UPDATE: This location is closed. Boo!\n",
      "8532    The bill was 150.00 and that was after a free ...\n",
      "7035    Totally excited to try this place out, my gran...\n",
      "6921    I never knew green chilies were more valuable ...\n",
      "1878    I went here with Friends last Friday.  All my ...\n",
      "5955    I've now tried Thai Elephant three times.  My ...\n",
      "1406    From my door, it's a five minute stroll throug...\n",
      "3677    Hands down, the single worst public mass trans...\n",
      "457     I was here for a conference and saw their sign...\n",
      "9640    Went here one night with a group of friends. T...\n",
      "3339    New N. Scottsdale location, Baaaaaaad!  The we...\n",
      "5121    Just isn't very good.\\n\\nI don't understand wh...\n",
      "6045    The cool name of the place is the only good th...\n",
      "8072    This place is the white-trash Chipotle. The fo...\n",
      "3755    Have been going to LGO since 2003 and have alw...\n",
      "8596    Nice facilities, nice AC, but two FATAL flaws:...\n",
      "1297    I dined at this restaurant on a Saturday morni...\n",
      "8910    Im going to have to agree Whole heartedly. And...\n",
      "7382    Thank you to Sarah L for bringing to my attent...\n",
      "4165    OMG! what is the rave about? this place is dis...\n",
      "4562    despite it's billing as the 'largest thrift st...\n",
      "7447    Ok..I told Amanda that anyplace that serves be...\n",
      "9396    Pros: \\n-No breed restrictions on dogs\\n-Washe...\n",
      "3723    When owners/staff changed we kept hoping for t...\n",
      "1159    I don't like the pizza hear and if you go for ...\n",
      "9846    NO.  Don't go. Don't do it.  This was my first...\n",
      "7975    What are you all talking about?! This place is...\n",
      "2084    Easily the worst \"burrito\" I have ever had.\\nI...\n",
      "2869    This used to be one of my favorite restaurants...\n",
      "2462    Every time I've been there they have messed up...\n",
      "5811    Not a company to do business with ... From my ...\n",
      "1270    Maybe I should have had a hot dog but I crave ...\n",
      "9953    \"Hipster,Trendy\" ????-I think NOT !!!! Very di...\n",
      "7397    This place sucks!! I moved to the valley and h...\n",
      "8569    This place has the oiliest food I've ever eate...\n",
      "4249    AMC Theaters has the distinct disadvantage in ...\n",
      "9287    I don't intend to return, but based on the way...\n",
      "7579    Ok, im not getting the great reviews on this p...\n",
      "4842    My fiance and I tried the place because of a G...\n",
      "5882    Tried Shorty's today, sadly it will be my one ...\n",
      "3357    I wrote a less than stellar review about this ...\n",
      "3028    My office moved to the area so I was driving a...\n",
      "113     Unless you are a regular or look like your wal...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print message text for the false positives\n",
    "pd.set_option('display.max_seq_items', 100)\n",
    "print X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that words like \"crave\", \"cool\", \"good\", \"enjoy\", \"rave\" and \"OMG\" were associated in the training model with good reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6376       They have a mechanical bull.  Need I say more?\n",
       "9622    I always buy my tires at Walmart, but they did...\n",
       "750     This store has the most pleasant employees of ...\n",
       "3052    When I met some friends for dinner at this res...\n",
       "4034    \"Fine dining\" is not just a setting.  it isn't...\n",
       "1323    I just wanted to add that in addition to party...\n",
       "5332    I had a great experience.  Nice people.   My m...\n",
       "6779    I had the terrible decision to make to euthani...\n",
       "9636    OK OK... as a Proud Italian I hope my momma do...\n",
       "6334    I came here today for a manicure and pedicure....\n",
       "7531    This was such a good experience\\nI was up all ...\n",
       "8053    My wife called to have our vent cleaned since ...\n",
       "1404    Excellent customer service, super clean, and t...\n",
       "2626    I highly reccomend this place. They helped my ...\n",
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the false negatives, it looks like, in some cases, words like \"horribly\", \"terrible\" and \"hate\" were associated with negative reviews in the training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "\n",
    "Let's pretend that you want to balance sensitivity and specificity. You can achieve this by changing the threshold for predicting a 5-star review. What threshold approximately balances sensitivity and specificity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         thresholds        diff\n",
      "count  4.290000e+02  429.000000\n",
      "mean   7.533549e-01    0.111128\n",
      "std    4.014394e-01    0.319762\n",
      "min    7.378070e-34   -1.000000\n",
      "25%    5.990707e-01   -0.144083\n",
      "50%    9.981564e-01    0.039496\n",
      "75%    9.999734e-01    0.306269\n",
      "max    2.000000e+00    1.000000\n"
     ]
    }
   ],
   "source": [
    "# create a list that will store the results of the process below\n",
    "# loop through the thresholds returned by the metrics.roc_curve function\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "#y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "tup = []\n",
    "for index, values in enumerate(thresholds):\n",
    "    sens = tpr[index]\n",
    "    spec = (1-fpr[index])\n",
    "    diff = sens - spec\n",
    "    X = [values,(sens-spec)]\n",
    "    tup.append(X)\n",
    "\n",
    "tup2 = pd.DataFrame(tup, columns = (['thresholds','diff']))\n",
    "print tup2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       thresholds      diff\n",
      "197  9.992959e-01  0.000085\n",
      "198  9.992907e-01  0.006145\n",
      "199  9.992675e-01  0.007312\n",
      "200  9.992113e-01  0.008479\n",
      "201  9.991539e-01  0.009646\n",
      "202  9.990188e-01  0.015707\n",
      "203  9.989971e-01  0.016874\n",
      "204  9.989804e-01  0.018040\n",
      "205  9.989342e-01  0.024101\n",
      "206  9.989260e-01  0.025268\n",
      "207  9.989067e-01  0.026435\n",
      "208  9.988824e-01  0.027602\n",
      "209  9.987814e-01  0.028768\n",
      "210  9.986288e-01  0.029935\n",
      "211  9.985812e-01  0.031102\n",
      "212  9.984684e-01  0.032269\n",
      "213  9.984102e-01  0.038330\n",
      "214  9.981564e-01  0.039496\n",
      "215  9.980696e-01  0.040663\n",
      "216  9.979370e-01  0.041830\n",
      "217  9.979265e-01  0.047891\n",
      "218  9.976636e-01  0.049058\n",
      "219  9.975982e-01  0.050225\n",
      "220  9.975611e-01  0.051391\n",
      "221  9.975466e-01  0.052558\n",
      "222  9.975335e-01  0.053725\n",
      "223  9.975272e-01  0.054892\n",
      "224  9.974970e-01  0.060953\n",
      "225  9.974948e-01  0.062119\n",
      "226  9.973739e-01  0.068180\n",
      "..            ...       ...\n",
      "399  7.456037e-05  0.705590\n",
      "400  6.048523e-05  0.711651\n",
      "401  5.634746e-05  0.717712\n",
      "402  4.639998e-05  0.723772\n",
      "403  3.891081e-05  0.729833\n",
      "404  3.081302e-05  0.735893\n",
      "405  2.292778e-05  0.741954\n",
      "406  2.163111e-05  0.748015\n",
      "407  2.124242e-05  0.754075\n",
      "408  1.467364e-05  0.760136\n",
      "409  1.181395e-05  0.766196\n",
      "410  5.551929e-06  0.772257\n",
      "411  3.598025e-06  0.778318\n",
      "412  3.370959e-06  0.784378\n",
      "413  2.835042e-06  0.790439\n",
      "414  2.648374e-06  0.791606\n",
      "415  2.436048e-06  0.797666\n",
      "416  2.182397e-06  0.798833\n",
      "417  1.369501e-06  0.804894\n",
      "418  1.287042e-06  0.810954\n",
      "419  9.758081e-07  0.817015\n",
      "420  8.536657e-07  0.823076\n",
      "421  3.799382e-07  0.829136\n",
      "422  2.600933e-07  0.835197\n",
      "423  2.167570e-07  0.841257\n",
      "424  1.632219e-07  0.847318\n",
      "425  1.462241e-07  0.853379\n",
      "426  6.825316e-08  0.854545\n",
      "427  3.837549e-08  0.860606\n",
      "428  7.378070e-34  1.000000\n",
      "\n",
      "[232 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# locate the minimum difference (at which sensitivity and specificity are balanced)\n",
    "# pick rows>0\n",
    "print tup2[tup2['diff']>0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity and specificity are balanced with threshold = 9.985983e-01 , with a sensitivity-specificity difference of 0.002253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "\n",
    "Let's see how well Naive Bayes performs when all reviews are included, rather than just 1-star and 5-star reviews:\n",
    "\n",
    "- Define X and y using the original DataFrame from step 1. (y should contain 5 different classes.)\n",
    "- Split the data into training and testing sets.\n",
    "- Calculate the testing accuracy of a Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy.\n",
    "- Print the confusion matrix.\n",
    "- Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y using the original DataFrame\n",
    "# define X and y\n",
    "X = yelp['text']\n",
    "y = yelp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 423)\t1\n",
      "  (0, 474)\t1\n",
      "  (0, 562)\t1\n",
      "  (0, 633)\t1\n",
      "  (0, 743)\t1\n",
      "  (0, 761)\t1\n",
      "  (0, 912)\t1\n",
      "  (0, 990)\t1\n",
      "  (0, 1080)\t2\n",
      "  (0, 1112)\t1\n",
      "  (0, 1145)\t1\n",
      "  (0, 1158)\t1\n",
      "  (0, 1204)\t1\n",
      "  (0, 1254)\t3\n",
      "  (0, 1275)\t13\n",
      "  (0, 1401)\t1\n",
      "  (0, 1461)\t2\n",
      "  (0, 1561)\t2\n",
      "  (0, 1562)\t1\n",
      "  (0, 1697)\t1\n",
      "  (0, 1749)\t1\n",
      "  (0, 1778)\t5\n",
      "  (0, 2386)\t1\n",
      "  (0, 2559)\t1\n",
      "  (0, 2711)\t1\n",
      "  :\t:\n",
      "  (7499, 1275)\t2\n",
      "  (7499, 2386)\t1\n",
      "  (7499, 3368)\t1\n",
      "  (7499, 3887)\t1\n",
      "  (7499, 8520)\t1\n",
      "  (7499, 8983)\t1\n",
      "  (7499, 9299)\t1\n",
      "  (7499, 10236)\t1\n",
      "  (7499, 11625)\t3\n",
      "  (7499, 12156)\t1\n",
      "  (7499, 12622)\t1\n",
      "  (7499, 13537)\t1\n",
      "  (7499, 14574)\t1\n",
      "  (7499, 15060)\t1\n",
      "  (7499, 15097)\t1\n",
      "  (7499, 15323)\t1\n",
      "  (7499, 16488)\t1\n",
      "  (7499, 16677)\t1\n",
      "  (7499, 17630)\t1\n",
      "  (7499, 18751)\t1\n",
      "  (7499, 20402)\t1\n",
      "  (7499, 22943)\t1\n",
      "  (7499, 22987)\t1\n",
      "  (7499, 23208)\t3\n",
      "  (7499, 24461)\t2\n",
      "  (0, 307)\t1\n",
      "  (0, 562)\t2\n",
      "  (0, 874)\t1\n",
      "  (0, 900)\t1\n",
      "  (0, 1150)\t1\n",
      "  (0, 1254)\t1\n",
      "  (0, 1275)\t5\n",
      "  (0, 1387)\t1\n",
      "  (0, 1561)\t4\n",
      "  (0, 1608)\t1\n",
      "  (0, 1698)\t1\n",
      "  (0, 1778)\t3\n",
      "  (0, 1971)\t1\n",
      "  (0, 2185)\t9\n",
      "  (0, 2252)\t1\n",
      "  (0, 2339)\t4\n",
      "  (0, 2386)\t1\n",
      "  (0, 2421)\t3\n",
      "  (0, 2424)\t1\n",
      "  (0, 2432)\t2\n",
      "  (0, 2637)\t2\n",
      "  (0, 3102)\t3\n",
      "  (0, 3103)\t1\n",
      "  (0, 3598)\t1\n",
      "  (0, 3600)\t3\n",
      "  :\t:\n",
      "  (2499, 22962)\t1\n",
      "  (2499, 22973)\t1\n",
      "  (2499, 23008)\t2\n",
      "  (2499, 23232)\t7\n",
      "  (2499, 23338)\t1\n",
      "  (2499, 23383)\t1\n",
      "  (2499, 23679)\t2\n",
      "  (2499, 23739)\t1\n",
      "  (2499, 24348)\t1\n",
      "  (2499, 24366)\t1\n",
      "  (2499, 24461)\t2\n",
      "  (2499, 24695)\t1\n",
      "  (2499, 24717)\t1\n",
      "  (2499, 24748)\t1\n",
      "  (2499, 24750)\t1\n",
      "  (2499, 24789)\t8\n",
      "  (2499, 24860)\t3\n",
      "  (2499, 24931)\t1\n",
      "  (2499, 24940)\t4\n",
      "  (2499, 25009)\t1\n",
      "  (2499, 25037)\t1\n",
      "  (2499, 25209)\t1\n",
      "  (2499, 25376)\t1\n",
      "  (2499, 25533)\t2\n",
      "  (2499, 25547)\t1\n"
     ]
    }
   ],
   "source": [
    "# create document-term matrices\n",
    "# import and instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "# fit and transform X_train, but only transform X_test\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "print X_train_dtm\n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4912\n"
     ]
    }
   ],
   "source": [
    "# calculate the testing accuary\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    855\n",
      "5    838\n",
      "3    384\n",
      "2    244\n",
      "1    179\n",
      "Name: stars, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    0.342\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the null accuracy\n",
    "print y_test.value_counts()\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58  22  16  65  18]\n",
      " [ 16  27  41 140  20]\n",
      " [  6   6  33 304  35]\n",
      " [  5   1  18 637 194]\n",
      " [  6   0   7 352 473]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "conf_mat=metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity =0.324022346369\n"
     ]
    }
   ],
   "source": [
    " #calculate sensitivity - True positive rate (for 1 star reviews)\n",
    "sum1 = conf_mat[0].sum()\n",
    "tp = conf_mat[0][0]\n",
    "sensitivity = tp/(sum1*1.0)\n",
    "print 'sensitivity =' + str(sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "specificity = 0.985981308411\n"
     ]
    }
   ],
   "source": [
    "# calculate specificity (1 - False Positive Rate)\n",
    "def sumf(l,n): \n",
    "    return l[n].sum()\n",
    "sum2 = 0\n",
    "for nl in range(1,5):\n",
    "    sum2 = sum2+sumf(conf_mat,nl)\n",
    "fp=0\n",
    "for x in range(1,5):\n",
    "    fp = fp+ conf_mat[x][0]\n",
    "print fp\n",
    "fpr2 = (fp*1.0)/(fp+sum2)\n",
    "specificity = 1-fpr2\n",
    "print 'specificity = ' + str(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: This model has a far lower accuracy rate (0.47) than the previous model (0.93). The problems seem to lie on the sensitivity side, with a very low true positive rate of 0.27. It does much better on the specificity side, with a specificity level of 0.985.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
